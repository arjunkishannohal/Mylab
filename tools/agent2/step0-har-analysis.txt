# Agent 2: HAR analysis (manual capture -> actionable testing data)
# Goal: Take a large .har (50-100+ requests) and extract high-value testing data into ONE file.
# Scope: ONLY analyze data you captured in-scope.

## Inputs
- Manual HAR capture(s): manual/har/*.har
- Recon outputs (from Agent 1):
  - outputs/activesubdomain.txt (scope allowlist)
  - outputs/reports/agent1-recon-report.md (agent1 decisions)
  - temp/agent1/all_urls.txt (merged URL corpus, if present)

## Outputs (Agent 2)
- outputs/agent2/important_data.txt (single consolidated extraction)
- outputs/agent2/agent2-har-report.md (summary + decisions + what to test first)
- outputs/agent2/har_summary.json (machine-readable summary for later automation)

## What Agent 2 must extract from HAR
1) Auth + session material (most important)
- Request headers:
  - Authorization (Bearer, Basic, custom)
  - X-API-Key / api-key / apikey
  - CSRF/XSRF tokens (x-csrf-token, x-xsrf-token, csrftoken)
- Cookies:
  - Session cookies (set-cookie + cookie)
  - Flags: Secure / HttpOnly / SameSite
- OAuth/JWT clues:
  - access_token / refresh_token / id_token in bodies
  - JWT-like strings (header.payload.signature)

2) High-value endpoints and flows
- Login/registration/password reset flows
- Profile/user/organization/account endpoints
- Admin endpoints
- File upload endpoints (multipart/form-data)
- API patterns:
  - /api, /v1, /v2
  - GraphQL (/graphql), WebSockets (ws/wss)

3) Inputs to fuzz (parameter & JSON keys)
- Query parameter names
- JSON body keys (top-level + nested keys if possible)
- Common IDs (userId, accountId, orgId, projectId, invoiceId)

4) Security signals
- Status codes distribution (200/302/401/403/404/429/5xx)
- CORS headers (Access-Control-*)
- Security headers presence (CSP, HSTS, X-Frame-Options, etc.)
- Redirect behavior (to out-of-scope domains)

5) Scope safety
- List any hostnames in the HAR that are NOT in outputs/activesubdomain.txt
  - Mark them as OUT-OF-SCOPE and do NOT include them in testing queues.

## Execution
1) Place your HAR file(s) into:
   - manual/har/

2) Run the analyzer (Windows):
   - python tools/agent2/har_analyzer.py --har manual/har/<file>.har

3) Review outputs:
   - outputs/agent2/important_data.txt
   - outputs/agent2/agent2-har-report.md

## Quality gate (mandatory)
- The analyzer MUST process ALL entries in the HAR.
- The report MUST include:
  - Total entries processed
  - Unique hosts seen
  - Unique endpoints (method + path) count
  - Auth materials found (types, not just raw dump)
  - Out-of-scope hosts list

## Optional: Agent 2 may create a custom HAR analyzer (allowed)
Sometimes the program type requires tailored extraction (e.g., GraphQL-heavy apps, mobile backends, SOAP/XML APIs).
Agent 2 is allowed to create its own analyzer script, as long as it follows these rules.

### When to create a custom analyzer
- The app uses GraphQL and you need to extract operationName/query/mutations.
- The app is API-only and you need deeper JSON schema/key harvesting.
- The app has multi-tenant headers (x-org-id / x-tenant-id) that must be tracked.
- You want to extract a specific auth scheme or request signing pattern.

### Where to put it
- Create a new file in tools/agent2/, for example:
	- tools/agent2/har_analyzer_custom.py

### Required behavior (must keep the same contract)
- MUST still take a .har as input.
- MUST still enforce scope using outputs/activesubdomain.txt (treat non-allowlisted hosts as OUT-OF-SCOPE).
- MUST still write these outputs (same filenames):
	- outputs/agent2/important_data.txt
	- outputs/agent2/agent2-har-report.md
	- outputs/agent2/har_summary.json
- MUST process ALL HAR entries and report counts.

### Safety rules (important)
- Do NOT dump full raw tokens/secrets into the report. Use redacted previews.
- Do NOT automatically generate new scanning targets from HAR unless they are in-scope.
- If the program is strict domain-only scope, treat any IPs/third-party hosts as informational only.

### Program-type tuning ideas (examples)
- GraphQL: extract endpoint paths (/graphql), operationName values, and top-level field names.
- REST: extract common object IDs and key parameter names; group endpoints by resource.
- OAuth/OIDC: extract redirect_uri, client_id, token endpoints, and PKCE-related parameters.
- File upload: list multipart endpoints and file field names.
