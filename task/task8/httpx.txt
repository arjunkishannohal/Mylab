# httpx (probe live web) — Task 2 Tool 1

Install
go install -v github.com/projectdiscovery/httpx/cmd/httpx@latest

Input (contract)
- outputs/activesubdomain.txt

Outputs (contract)
- outputs/live_base_urls.txt   (scheme://host[:port])
- outputs/live_seeds.txt       (optional extra metadata / raw output)
 - outputs/cariddi/cariddi_findings.txt        (cariddi raw findings)
 - outputs/cariddi/cariddi_urls_in_scope.txt   (scope-filtered URLs extracted from cariddi output)
 - outputs/url_corpus_all_in_scope.txt         (combined URL corpus; created/updated)

Run (PowerShell; from repo root)
New-Item -ItemType Directory -Force temp/agent1 | Out-Null
New-Item -ItemType Directory -Force outputs | Out-Null

# Basic probe (fast, aggressive discovery)
httpx -l outputs/activesubdomain.txt -silent -timeout 9 -retries 1 -threads 50 -o outputs/live_base_urls.txt

# ------------------------------------------------------------
# Cariddi enrichment (runs as part of Task 8)
# ------------------------------------------------------------
# Goal: crawl from live seeds and hunt for secrets/errors/info/endpoints.
# NOTE: cariddi is GPL-3.0; install it externally (don’t vendor).
#
# Install
#   go install -v github.com/edoardottt/cariddi/cmd/cariddi@latest
# Verify
#   cariddi -version
#
# Preconditions
#   if (!(Test-Path outputs\live_base_urls.txt)) { throw "Missing outputs\\live_base_urls.txt" }
#   if (!(Test-Path outputs\activesubdomain.txt)) { throw "Missing outputs\\activesubdomain.txt" }
#
# Outputs
#   outputs\cariddi\cariddi_findings.txt
#   outputs\cariddi\cariddi_urls_in_scope.txt
#   outputs\url_corpus_all_in_scope.txt  (UPDATED/CREATED: merged canonical URL corpus)

New-Item -ItemType Directory -Force outputs\cariddi | Out-Null

# Recommended baseline (bounded to keep under the 9-minute rule)
# -e    : endpoints hunting
# -s    : secrets hunting (regex-based; expect FP/FN)
# -err  : error hunting
# -info : useful info hunting
# -md 2 : max depth 2
# -c 30 : concurrency
# -t 10 : timeout seconds
# -plain: keep output easy to parse

Get-Content outputs\live_base_urls.txt |
  cariddi -e -s -err -info -md 2 -c 30 -t 10 -plain |
  Tee-Object -FilePath outputs\cariddi\cariddi_findings.txt

# Extract URLs from findings (deterministic)
Select-String -Path outputs\cariddi\cariddi_findings.txt -Pattern 'https?://[^\s"''<>]+' -AllMatches |
  ForEach-Object { $_.Matches.Value } |
  ForEach-Object { $_.Trim().TrimEnd('.', ',', ';') } |
  Where-Object { $_ } |
  Sort-Object -Unique |
  Set-Content -Encoding utf8 outputs\cariddi\cariddi_urls_raw.txt

# Allowlist-filter URLs (scope safe)
python task\task21\allowlist_filter_urls.py --allowlist outputs\activesubdomain.txt --in outputs\cariddi\cariddi_urls_raw.txt --out outputs\cariddi\cariddi_urls_in_scope.txt

# MANDATORY MERGE: promote cariddi URLs into the canonical URL corpus
if (Test-Path outputs\url_corpus_all_in_scope.txt) {
  Get-Content outputs\url_corpus_all_in_scope.txt, outputs\cariddi\cariddi_urls_in_scope.txt |
    Where-Object { $_ } |
    ForEach-Object { $_.Trim() } |
    Where-Object { $_ } |
    Sort-Object -Unique |
    Set-Content -Encoding utf8 outputs\url_corpus_all_in_scope.txt
} else {
  Copy-Item outputs\cariddi\cariddi_urls_in_scope.txt outputs\url_corpus_all_in_scope.txt
}

Run for EVERY URL in a file (URL list mode)
# Use this when your input file contains full URLs (with scheme, and optionally paths/query), one per line.
# Example input file: temp/agent1/url_list.txt
# Notes:
# - If the line is a full URL, httpx will request that exact URL.
# - If the line is only a host, httpx will probe default ports/schemes.

# PowerShell:
# httpx -l temp/agent1/url_list.txt -silent -timeout 9 -retries 1 -threads 50 -o temp/agent1/httpx_urls_out.txt

# Optional: keep a richer “seeds” file (status/title/server)
# httpx -l outputs/activesubdomain.txt -silent -timeout 9 -retries 1 -threads 50 -status-code -title -server -tech-detect -o outputs/live_seeds.txt

9-minute rule (batch mode)
# If activesubdomain.txt is large, split into chunks and append.
# PowerShell:
$chunkDir = 'temp/agent1/httpx_chunks'
New-Item -ItemType Directory -Force $chunkDir | Out-Null
Get-Content outputs/activesubdomain.txt | Where-Object { $_ } | ForEach-Object { $_.Trim() } |
  Split-Path -Leaf | Out-Null

# Simple chunking without extra tools (2000 lines per chunk)
$i = 0
Get-Content outputs/activesubdomain.txt | Where-Object { $_ } | ForEach-Object {
  $line = $_.Trim()
  if ($line) {
    $file = Join-Path $chunkDir ("chunk_{0:D4}.txt" -f [math]::Floor($i / 2000))
    Add-Content -Encoding ascii $file $line
    $i++
  }
}

Remove-Item -ErrorAction SilentlyContinue outputs/live_base_urls.txt
Get-ChildItem $chunkDir -Filter 'chunk_*.txt' | Sort-Object Name | ForEach-Object {
  httpx -l $_.FullName -silent -timeout 9 -retries 1 -threads 50 -o temp/agent1/_httpx_tmp.txt
  Get-Content temp/agent1/_httpx_tmp.txt | Add-Content outputs/live_base_urls.txt
}
Remove-Item -ErrorAction SilentlyContinue temp/agent1/_httpx_tmp.txt
Get-Content outputs/live_base_urls.txt | Sort-Object -Unique | Set-Content -Encoding utf8 outputs/live_base_urls.txt

Notes
- This probes default web ports (80/443) from hostnames.
- Keep results scope-safe by only feeding allowlisted hosts.
