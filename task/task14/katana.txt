# Tool 14 — katana (crawler) — STRICT RUN-CARD
# Goal: crawl in-scope live URLs and produce a URL corpus for further analysis.
# Inputs (contract):
#   - outputs/live_base_urls.txt            (scheme://host)  [required]
#   - outputs/live_hostport_urls.txt        (scheme://host:port) [optional]
# Outputs (contract):
#   - temp/agent1/katana_urls_raw.txt
#   - outputs/katana_urls.txt               (deduped final)
#   - temp/agent1/logs/katana_YYYYMMDD_HHMMSS.log
# Time rule: keep each command under ~9 minutes (batch if needed).

# ----------------------------
# 0) Preconditions
# ----------------------------
# - use apporch by we can get maximum results.
# Only collect URLs for targets in scope.
# - Public sources may include out-of-scope hosts in URLs; filter later using your allowlist.

# ----------------------------
# 1) Install / verify
# ----------------------------
# Option A (recommended): via go
#   go install -v github.com/projectdiscovery/katana/cmd/katana@latest
#   katana -version
#
# Verify flags for your version:
#   katana -h

# ----------------------------
# 2) STRICT preflight + seed list
# ----------------------------
#   New-Item -ItemType Directory -Force temp\agent1 | Out-Null
#   New-Item -ItemType Directory -Force temp\agent1\logs | Out-Null
#   New-Item -ItemType Directory -Force outputs | Out-Null
#   if (!(Test-Path outputs\live_base_urls.txt)) { throw "Missing outputs\\live_base_urls.txt" }
#
# Build a single seeds file (strict + deterministic):
#   Remove-Item -ErrorAction SilentlyContinue temp\agent1\katana_seeds_urls.txt
#   Get-Content outputs\live_base_urls.txt | Where-Object { $_ -and $_.Trim() -ne "" } | ForEach-Object { $_.Trim() } | Add-Content temp\agent1\katana_seeds_urls.txt
#   if (Test-Path outputs\live_hostport_urls.txt) {
#     Get-Content outputs\live_hostport_urls.txt | Where-Object { $_ -and $_.Trim() -ne "" } | ForEach-Object { $_.Trim() } | Add-Content temp\agent1\katana_seeds_urls.txt
#   }
#   Get-Content temp\agent1\katana_seeds_urls.txt | Sort-Object -Unique | Set-Content temp\agent1\katana_seeds_urls.txt
#   $n = (Get-Content temp\agent1\katana_seeds_urls.txt).Count
#   if ($n -lt 1) { throw "No seeds found in temp\\agent1\\katana_seeds_urls.txt" }
#   Write-Host "[katana] seeds: $n"
#
# Log file
#   $ts = Get-Date -Format 'yyyyMMdd_HHmmss'
#   $log = "temp\\agent1\\logs\\katana_$ts.log"
#   "[katana] start $ts" | Set-Content $log
#
# Reset outputs
#   Remove-Item -ErrorAction SilentlyContinue temp\agent1\katana_urls_raw.txt
#   Remove-Item -ErrorAction SilentlyContinue outputs\katana_urls.txt

# ----------------------------
# 3) Crawl (baseline)
# ----------------------------
# Keep the baseline minimal to avoid version-specific flag mismatches.
#
#   katana -list temp\agent1\katana_seeds_urls.txt -silent -o temp\agent1\_katana_part.txt 2>&1 | Tee-Object -FilePath $log -Append
#   if (Test-Path temp\agent1\_katana_part.txt) { Get-Content temp\agent1\_katana_part.txt | Add-Content temp\agent1\katana_urls_raw.txt; Remove-Item temp\agent1\_katana_part.txt }
#
# Optional tuning (ONLY if your katana supports these flags; confirm via `katana -h`):
# - depth (examples): -d 2 or -depth 2
# - concurrency (examples): -c 10 or -concurrency 10
# - rate limit (examples): -rl 50 or -rate-limit 50
# - timeout (examples): -timeout 9

# ----------------------------
# 4) Finalize (dedupe)
# ----------------------------
#   if (!(Test-Path temp\agent1\katana_urls_raw.txt)) { Write-Host "[katana] No raw output yet (crawl found nothing or failed)." }
#   if (Test-Path temp\agent1\katana_urls_raw.txt) {
#     Get-Content temp\agent1\katana_urls_raw.txt |
#       Where-Object { $_ -and $_.Trim() -ne "" } |
#       ForEach-Object { $_.Trim() } |
#       Sort-Object -Unique |
#       Set-Content outputs\katana_urls.txt
#   }

# ----------------------------
# 4B) If Swagger/OpenAPI docs are found 
# ----------------------------
# Katana often discovers links like:
#   /swagger.json  /openapi.json  /v3/api-docs  /swagger/v1/swagger.json  /api-docs
#
# If you spot these in outputs\katana_urls.txt:
# 1) Save them to a docs URL list (only keep in-scope hosts):
#   Get-Content outputs\katana_urls.txt | Select-String -Pattern 'swagger\.json|openapi\.json|api-docs|swagger' | ForEach-Object { $_.Line } | Set-Content outputs\api_docs_urls.txt
# 2) Optional (info-gathering): extract endpoints from those docs:
#   python tools\agent1\assets\openapi_extractor.py --docs outputs\api_docs_urls.txt --allowlist outputs\activesubdomain.txt --out outputs\api_endpoints_from_openapi.txt --raw-dir temp\agent1\api_docs_raw

# ----------------------------
# 5) 9-minute batching (PowerShell)
# ----------------------------
# Use this if seeds are large or katana runs longer than your environment timeout.
#
# Create chunks:
#   $in = 'temp\\agent1\\katana_seeds_urls.txt'
#   $chunkSize = 500
#   $outDir = 'temp\\agent1\\chunks_katana'
#   New-Item -ItemType Directory -Force $outDir | Out-Null
#   $lines = Get-Content $in
#   $i = 0
#   for ($p = 0; $p -lt $lines.Count; $p += $chunkSize) {
#     $chunk = $lines[$p..([Math]::Min($p+$chunkSize-1, $lines.Count-1))]
#     $chunkPath = Join-Path $outDir ("chunk_{0:d4}.txt" -f $i)
#     $chunk | Set-Content $chunkPath
#     $i++
#   }
#
# Run per chunk (append raw):
#   Remove-Item -ErrorAction SilentlyContinue temp\\agent1\\katana_urls_raw.txt
#   Get-ChildItem $outDir -Filter 'chunk_*.txt' | Sort-Object Name | ForEach-Object {
#     $chunk = $_.FullName
#     Write-Host "[katana] crawling $chunk"
#     katana -list $chunk -silent -o temp\\agent1\\_katana_part.txt 2>&1 | Tee-Object -FilePath $log -Append
#     if (Test-Path temp\\agent1\\_katana_part.txt) {
#       Get-Content temp\\agent1\\_katana_part.txt | Add-Content temp\\agent1\\katana_urls_raw.txt
#       Remove-Item temp\\agent1\\_katana_part.txt
#     }
#   }
#
# After batching, run section 4 to dedupe -> final.
